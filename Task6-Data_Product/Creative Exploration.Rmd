---
title: "Task 5 - Creative Exploration"
author: "Ruchira Senanayake"
date: "6/28/2020"
output: html_document
---
 
# Introduction
 
So far you have used basic models to understand and predict words. In this next task, your goal is to use all the resources you have available to you (from the Data Science Specialization, resources on the web, or your own creativity) to improve the predictive accuracy while reducing computational runtime and model complexity (if you can). Be sure to hold out a test set to evaluate the new, more creative models you are building.

**Tasks to accomplish**

  1.Explore new models and data to improve your predictive model.
  
  2.Evaluate your new predictions on both accuracy and efficiency.

**Questions to consider**

  1.What are some alternative data sets you could consider using?
  
  2.What are ways in which the n-gram model may be inefficient?
  
  3.What are the most commonly missed n-grams? Can you think of a reason why they would be missed and fix that?
  
  4.What are some other things that other people have tried to improve their model?
  
  5.Can you estimate how uncertain you are about the words you are predicting?

## Loading The Required Packages

```{r load packages, warning=FALSE, message=FALSE, comment=""}
library(tidyverse)
library(stringr)
library(dplyr)
library(tidytext)
library(tidyverse)
library(tokenizers)
library(tidyr)
```

## Loading The Data

```{r load data, warning=FALSE, message=FALSE, eval=FALSE, comment=""}
# Reading the data files
blogs <- readLines("en_US.blogs.txt", skipNul = TRUE, encoding="UTF-8")
news <- readLines("en_US.news.txt", skipNul = TRUE, encoding="UTF-8")
twitter <- readLines("en_US.twitter.txt", skipNul = TRUE, encoding="UTF-8")

# Removing Non English Words
blogs <- iconv(blogs,"latin1","ASCII",sub="")
news <- iconv(news,"latin1","ASCII",sub="")
twitter <- iconv(twitter,"latin1","ASCII",sub="")

# Creating Dataframes
blogs   <- data_frame(text = blogs)
news    <- data_frame(text = news)
twitter <- data_frame(text = twitter)
```

### Sampling The Data

```{r sampling, warning=FALSE, message=FALSE, eval=FALSE, comment=""}
set.seed(1001)
sample_pct <- 0.15

blogs_sample <- blogs %>%
  sample_n(., nrow(blogs)*sample_pct)
news_sample <- news %>%
  sample_n(., nrow(news)*sample_pct)
twitter_sample <- twitter %>%
  sample_n(., nrow(twitter)*sample_pct)

# Creating tidy repository
repo_sample <- bind_rows(mutate(blogs_sample, source = "blogs"),
                         mutate(news_sample,  source = "news"),
                         mutate(twitter_sample, source = "twitter")) 
repo_sample$source <- as.factor(repo_sample$source)


# Cleaning up
rm(list = c("blogs", "blogs_file", "blogs_sample","news", "news_file",     
            "news_sample", "sample_pct", "twitter","twitter_file", 
            "twitter_sample"))
```

### Cleaning The sample data

```{r tidy_rep, warning=FALSE, message=FALSE, eval=FALSE, comment=""}

# Create filters: non-alphanumeric’s, url’s, repeated letters(+3x)
replace_reg <- "[^[:alpha:][:space:]]*"
replace_url <- "http[^[:space:]]*"
replace_aaa <- "\\b(?=\\w*(\\w)\\1)\\w+\\b"  

# Clean the sample. Cleaning is separted from tidying so unnest_tokens function can be used for words, and ngrams.
clean_sample <-  repo_sample %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  mutate(text = str_replace_all(text, replace_url, "")) %>%
  mutate(text = str_replace_all(text, replace_aaa, "")) %>% 
  mutate(text = iconv(text, "ASCII//TRANSLIT"))

rm(list = c("repo_sample"))
```

### Creating All The N-grams

```{r n-grams, warning=FALSE, message=FALSE, eval=FALSE, comment=""}
# Bigrams
bigram_repo <- clean_sample  %>%
  unnest_tokens(bigram, text, token = "ngrams", n = 2)

# Trigrams
trigram_repo <- clean_sample  %>%
  unnest_tokens(trigram, text, token = "ngrams", n = 3)

# Quadgrams
quadgram_repo <- clean_sample  %>%
  unnest_tokens(quadgram, text, token = "ngrams", n = 4)

# Quintgrams
quintgram_repo <- clean_sample  %>%
  unnest_tokens(quintgram, text, token = "ngrams", n = 5)

# Sextgrams
sextgram_repo <- clean_sample  %>%
  unnest_tokens(sextgram, text, token = "ngrams", n = 6)
```

### Reducing The N-grams Files

```{r reduce_ngrams, warning=FALSE, message=FALSE, eval=FALSE, comment=""}

# Bigrams
bigram_cover <- bigram_repo %>%
  count(bigram) %>%  
  filter(n > 10) %>%
  arrange(desc(n))  
rm(list = c("bigram_repo"))

# Trigrams
trigram_cover <- trigram_repo %>%
  count(trigram) %>%  
  filter(n > 10) %>%
  arrange(desc(n))  
rm(list = c("trigram_repo"))

# Quadgrams
quadgram_cover <- quadgram_repo %>%
  count(quadgram) %>%  
  filter(n > 10) %>%
  arrange(desc(n))  
rm(list = c("quadgram_repo"))

# Quintgrams
quintgram_cover <- quintgram_repo %>%
  count(quintgram) %>%  
  filter(n > 10) %>%
  arrange(desc(n))  
rm(list = c("quintgram_repo"))

# Sextgrams
sextgram_cover <- sextgram_repo %>%
  count(sextgram) %>%  
  filter(n > 10) %>%
  arrange(desc(n))  
rm(list = c("sextgram_repo"))
```

### Separating The Words

```{r separating Words, warning=FALSE, message=FALSE, eval=FALSE, comment=""}

bi_words <- bigram_cover %>%
  separate(bigram, c("word1", "word2"), sep = " ")

tri_words <- trigram_cover %>%
  separate(trigram, c("word1", "word2", "word3"), sep = " ")

quad_words <- quadgram_cover %>%
  separate(quadgram, c("word1", "word2", "word3", "word4"), sep = " ")

quint_words <- quintgram_cover %>%
  separate(quintgram, c("word1", "word2", "word3", "word4", "word5"), sep = " ")

sext_words <- sextgram_cover %>%
  separate(sextgram, c("word1", "word2", "word3", "word4", "word5", "word6"), sep = " ")

# Save data 

saveRDS(bi_words, "Words/bi_words_fast.rds")
saveRDS(tri_words, "Words/tri_words_fast.rds")
saveRDS(quad_words,"Words/quad_words_fast.rds")
saveRDS(quint_words,"Words/quint_words_fast.rds")
saveRDS(sext_words,"Words/sext_words_fast.rds")
```

### Loading The Separated Words

```{r separated Words, warning=FALSE, message=FALSE, comment=""}
bi_words <- readRDS("Words/bi_words_fast.rds")
tri_words  <- readRDS("Words/tri_words_fast.rds")
quad_words <- readRDS("Words/quad_words_fast.rds")
quint_words <- readRDS("Words/quint_words_fast.rds")
sext_words <- readRDS("Words/sext_words_fast.rds")
```

## Creating The Ngram Matching Functions

```{r ngram functions, warning=FALSE, message=FALSE, comment=""}
bigram <- function(input_words){
                    num <- length(input_words)
                    filter(bi_words, 
                          word1==input_words[num]) %>% 
                    top_n(1, n) %>%
                    filter(row_number() == 1L) %>%
                    select(num_range("word", 2)) %>%
                    as.character() -> out
                    ifelse(out =="character(0)", "?", return(out))
}

trigram <- function(input_words){
                    num <- length(input_words)
                    filter(tri_words, 
                            word1==input_words[num-1], 
                            word2==input_words[num])  %>% 
                    top_n(1, n) %>%
                    filter(row_number() == 1L) %>%
                    select(num_range("word", 3)) %>%
                    as.character() -> out
                    ifelse(out=="character(0)", bigram(input_words), return(out))
}

quadgram <- function(input_words){
                    num <- length(input_words)
                    filter(quad_words, 
                            word1==input_words[num-2], 
                            word2==input_words[num-1], 
                            word3==input_words[num])  %>% 
                    top_n(1, n) %>%
                    filter(row_number() == 1L) %>%
                    select(num_range("word", 4)) %>%
                    as.character() -> out
                    ifelse(out=="character(0)", trigram(input_words), return(out))
}

quintgram <- function(input_words){
  num <- length(input_words)
  filter(quint_words, 
         word1==input_words[num-3], 
         word2==input_words[num-2], 
         word3==input_words[num-1],
         word4==input_words[num])  %>% 
    top_n(1, n) %>%
    filter(row_number() == 1L) %>%
    select(num_range("word", 5)) %>%
    as.character() -> out
  ifelse(out=="character(0)", quadgram(input_words), return(out))
}

sextgram <- function(input_words){
  num <- length(input_words)
  filter(sext_words, 
         word1==input_words[num-4], 
         word2==input_words[num-3], 
         word3==input_words[num-2],
         word4==input_words[num-1],
         word5==input_words[num])  %>% 
    top_n(1, n) %>%
    filter(row_number() == 1L) %>%
    select(num_range("word", 6)) %>%
    as.character() -> out
  ifelse(out=="character(0)", quintgram(input_words), return(out))
}
```

## Creating The User Input And Data Cleaning Function

```{r user input, warning=FALSE, message=FALSE, comment=""}
ngrams <- function(input){
  # Create a dataframe
  input <- data.frame(text = input)
  # Clean the Inpput
  replace_reg <- "[^[:alpha:][:space:]]*"
  input <- input %>%
    mutate(text = str_replace_all(text, replace_reg, ""))
  # Find word count, separate words, lower case
  input_count <- str_count(input, boundary("word"))
  input_words <- unlist(str_split(input, boundary("word")))
  input_words <- tolower(input_words)
  # Call the matching functions
  out <- ifelse(input_count == 1, bigram(input_words), 
                ifelse (input_count == 2, trigram(input_words), 
                        ifelse(input_count == 3, quadgram(input_words),
                               ifelse(input_count == 4, quintgram(input_words), sextgram(input_words)))))
  # Output
  return(out)
}
```

## User Input and Program Output

```{r test output, warning=FALSE, message=FALSE, comment=""}
input <- "In case of a"
ngrams(input)
```
